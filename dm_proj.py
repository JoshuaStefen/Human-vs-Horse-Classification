# -*- coding: utf-8 -*-
"""DM_Proj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k4xofH40hhnQZmlvvmDDt2N-J9yVdidR
"""

# data visualization
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf
import tensorflow_datasets as tfds
import os
from tf.keras.models import load_model
from tf.keras.preprocessing.image import ImageDataGenerator
from tf.keras.models import Sequential
from tf.keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tf.keras.optimizers import Adam
from tf.keras.preprocessing import image
from tf.keras.utils import load_img
from PIL import Image


# download dataset
dataset, info = tfds.load('horses_or_humans', with_info=True, as_supervised=True)
info
dataset
class_names = info.features['label'].names
class_names




dataset
for i, example in enumerate(dataset['train']):
  image,label = example[0], example[1]
  save_dir = './horse-or-human/train/{}'.format(class_names[label])
  os.makedirs(save_dir, exist_ok=True)

  filename = '{}_{}.jpg'.format(class_names[label], i)
  filepath = save_dir + "/" + filename

  tf.keras.preprocessing.image.save_img(filepath, image)
  # break
for i, example in enumerate(dataset['test']):
  image,label = example[0], example[1]
  save_dir = './horse-or-human/test/{}'.format(class_names[label])
  os.makedirs(save_dir, exist_ok=True)

  filename = '{}_{}.jpg'.format(class_names[label], i)
  filepath = save_dir + "/" + filename

  tf.keras.preprocessing.image.save_img(filepath, image)
  # break
train_dir = '/content/horse-or-human/train'
image_size = (300, 300)
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1/255)
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = image_size,
    batch_size = batch_size,
    class_mode = 'binary'
)

test_dir = '/content/horse-or-human/test'
test_datagen = ImageDataGenerator(rescale=1/255)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size = image_size,
    batch_size = batch_size,
    class_mode = 'binary'
)

train_generator.class_indices

train_generator.filenames[:5], train_generator.filenames[-5:]

train_generator.samples

nrows = 2
ncols = 6
fig = plt.gcf()
fig.set_size_inches(ncols*4, nrows*4) # 16x8

next_batch = train_generator.next()
for i in range(0, nrows*ncols):
  ax = plt.subplot(nrows, ncols, i+1)
  ax.axis('Off')
  plt.imshow(next_batch[0][i])

plt.show()

def get_model():
  model = Sequential()
  # 1st layer CNN
  model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(300,300,3)))
  model.add(MaxPool2D(pool_size=2))

  # 2nd layer CNN
  model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))
  model.add(MaxPool2D(pool_size=2))

  # 3rd layer CNN
  model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
  model.add(MaxPool2D(pool_size=2))

  # flatten layers and FCN
  model.add(Flatten())
  model.add(Dense(512, activation='relu'))

  model.add(Dense(1, activation='sigmoid'))

  return model

model = get_model()
model.summary()

model.layers

model.layers[0].name

weights, biases = model.layers[0].get_weights()

len(biases)

model.layers[1].get_weights()

model = get_model()
adam = tf.keras.optimizers.Adam(learning_rate=0.001)
rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.0001)
adamax = tf.keras.optimizers.Adamax(learning_rate=0.0001)
model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_generator, epochs=5, validation_data=test_generator)

history.history

# plot loss and accuracy curve
fix, ax = plt.subplots(2,1)
ax[0].plot(history.history['loss'], color='b', label='Training Loss')
ax[0].plot(history.history['val_loss'], color='r', label='Validation Loss')
ax[0].legend(loc='best')

ax[1].plot(history.history['accuracy'], color='b', label='Training accuracy')
ax[1].plot(history.history['val_accuracy'], color='r', label='Validation accuracy')
ax[1].legend(loc='best')
# save model
model.save('horse-or-human.h5')
# load model
model_load = load_model('horse-or-human.h5')

img = image.load_img('/content/horse-or-human/test/humans/humans_111.jpg', target_size=image_size)
img = image.img_to_array(img)
img = np.expand_dims(img, axis=0)
img = img/255


# predict
prediction = model_load.predict(img)
print(prediction)

TH = 0.5
predicted_class = int(prediction[0][0]>TH)

class_indices = train_generator.class_indices
labels={v:k for k,v in class_indices.items()}
labels[predicted_class]